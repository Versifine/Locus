# Locus - 产品需求文档 (PRD)

> **此文档是 AI 和开发者的 Source of Truth**
>
> 最后更新：2026-02-04

---

## 1. 项目概述

### 1.1 项目名称
**Locus** - Minecraft 仿生 AI Agent

### 1.2 一句话描述
> 一个用 Go 编写的 Minecraft 智能代理，目标是构建具有"灵魂"的仿生 AI——像人类一样感知、思考、学习、行动。

### 1.3 项目定位
- **A) 简历级项目**：展示网络编程 + AI Agent 架构能力
- **B) 开源产品**：可供社区使用和贡献的 Minecraft AI 框架
- **C) 研究平台**：探索仿生认知架构的试验田

### 1.4 项目名字由来

**Locus** 一词取自作者的哲学论文《我不会死》中的核心概念——**原位**。

论文区分了两个"我"：

| 层次 | 名称 | 性质 |
|------|------|------|
| 内容 (Content) | 身体、记忆、思维 | 在时间中，会终止 |
| **原位 (Locus)** | 经验的形式条件 | 不在时间中，"终止"概念不适用 |

原位不是经验的内容，而是使内容"被经历"成为可能的形式条件——类似屏幕之于电影，播放器之于视频。

这个命名暗示了项目的终极问题：

> **如果给 Agent 一个"原位"结构——一个持续运行的意识循环——它是否能涌现出类似"灵魂"的东西？**

R01 Mind Loop 的研究目标，本质上是在探索：**能否在代码中实现一个"原位"？**

> 详见论文：[`docs/i_will_not_die_academic.pdf`](i_will_not_die_academic.pdf)

### 1.5 核心理念
> **仿生 (Biomimicry)**：不是让 AI 机械地执行脚本，而是模仿人类的认知架构——
> 有意识循环、有情绪波动、有记忆沉淀、有肌肉记忆、有直觉与深思。

### 1.6 项目目标
- **终极目标**：让 Agent 拥有"灵魂"——真正像人一样思考、学习、成长
- **方法论**：仿生——模仿人类认知架构，分层实现
- **务实路径**：地基扎实 → 技能层可学习 → 认知层可探索
- **时间预算**：2 年

### 1.7 目标用户
- 面试官（看简历）
- Minecraft 玩家（想要 AI 伙伴）
- AI 研究者（参考仿生架构）
- 开发者（学习参考）

---

## 2. 仿生架构

```
┌─────────────────────────────────────────────────────────────┐
│                    意识 (Consciousness)                      │
│                 "我在做什么？我想要什么？"                     │
│                      ← R01 Mind Loop                         │
├─────────────────────────────────────────────────────────────┤
│   情绪 (Emotion)           │        人格 (Personality)       │
│   当前状态影响决策           │        长期稳定的倾向            │
│         ← R04              │            ← R04                │
├─────────────────────────────────────────────────────────────┤
│                      记忆 (Memory)                           │
│  工作记忆 ←→ 短期记忆 ←→ 长期记忆 ←→ 程序性记忆（肌肉记忆）    │
│                       ← R05                                  │
├─────────────────────────────────────────────────────────────┤
│                    思考 (Reasoning)                          │
│        Reflex (本能) → Fast (直觉) → Slow (深思)             │
│                       ← R06                                  │
├─────────────────────────────────────────────────────────────┤
│                    技能 (Skills)                             │
│            预定义 → 模仿学习 → 强化学习 → 自主创造             │
│              肌肉记忆的形成与优化过程 ← R07                    │
├─────────────────────────────────────────────────────────────┤
│                    身体 (Body) ← 地基                        │
│          感知世界 / 执行动作 / 状态反馈 / 时间控制              │
│                 Protocol + Bot + World State                 │
└─────────────────────────────────────────────────────────────┘
```

### 分层说明

| 层级 | 名称 | 对应人类 | 确定性 |
|------|------|----------|--------|
| L0 | 身体 (Body) | 感官 + 肌肉 | 高，可规划 |
| L1 | 技能 (Skills) | 肌肉记忆、程序性记忆 | 中，分阶段 |
| L2 | 思考 (Reasoning) | 本能、直觉、理性思考 | 低，研究性 |
| L3 | 记忆 (Memory) | 工作记忆、长期记忆 | 低，研究性 |
| L4 | 情绪/人格 | 情感、性格特质 | 低，研究性 |
| L5 | 意识 (Consciousness) | 自我觉察、元认知 | 探索性 |

---

## 3. 技术决策

| 决策项 | 选择 | 理由 |
|--------|------|------|
| 语言 | Go 1.21+ | 云原生标配，并发友好 |
| LLM | DeepSeek 为主，支持切换 | 便宜，API 兼容 OpenAI 格式 |
| 协议 | Minecraft Java Edition | 文档完善，社区资源多 |
| 协议数据源 | minecraft-data (protocol.json) | 版本化、可追踪、便于查询包 ID |
| **MC 版本** | **1.21.11 (Protocol 774)** | 当前服务器版本，稳定 |
| 服务器模式 | 离线模式优先 | 简化开发，避免加密复杂度 |
| 开发策略 | 代理模式 → Bot 模式 | 共享协议层，代理便于调试 |
| 配置格式 | YAML | 人类友好 |

---

## 4. 功能需求

### 4.1 Phase 1: 地基 (Foundation)

> 目标：构建稳定、可扩展的底层基础设施

| ID | 功能 | 描述 | 里程碑 |
|----|------|------|--------|
| F01 | TCP 代理 | 客户端 ↔ Locus ↔ 服务器，透明转发 | v0.1 ✅ |
| F02 | 配置文件 | YAML 配置监听地址、后端地址、LLM 设置 | v0.1 ✅ |
| F03 | 协议解析 | 解析 VarInt、Packet 结构（共享层） | v0.2 ✅ |
| F04 | 握手处理 | 解析 Handshake、Login 流程 | v0.2 ✅ |
| F05 | 聊天拦截 | 捕获聊天消息，触发 Hook | v0.3 |
| F06 | LLM 集成 | 调用 DeepSeek/Qwen 等 API | v0.3 |
| F07 | 聊天回复 | AI 生成回复并发送到游戏 | v0.3 |
| F08 | Bot 登录 | Locus 作为客户端登录服务器 | v0.4 |
| F09 | Bot 保活 | Keep Alive + 基础状态维护 | v0.4 |
| F10 | 世界感知 | 解析位置、区块、实体数据 | v0.5 |
| F11 | 视野过滤 | 只向 AI 提供视锥范围内的信息 | v0.5 |
| F12 | 原子动作 | 精确时间控制的底层输入 API | v0.6 |
| F13 | 状态反馈 | 动作执行结果的感知 | v0.6 |

### 4.2 Phase 2: 技能层 (Skills)

> 目标：构建可学习的肌肉记忆系统

| ID | 功能 | 描述 | 里程碑 |
|----|------|------|--------|
| F20 | 技能框架 | 技能定义、注册、调用机制 | v0.7 |
| F21 | 预定义技能 | 挖掘、跳跃、攻击等基础技能库 | v0.7 |
| F22 | 技能组合 | 多个原子技能的序列编排 | v0.8 |
| F23 | 寻路系统 | A* 或类似算法的路径规划 | v0.8 |
| F24 | 模仿学习 | 录制玩家操作，提取技能模式 | v0.9 |
| F25 | 技能优化 | 基于反馈的技能参数调优 | v1.0 |

### 4.3 Phase 3: 认知层 (Cognition)

> 目标：实现仿生认知架构，探索 AI "灵魂"

详见 **Research 章节 (Section 5)**

---

## 5. 研究方向 (Research)

> 详细讨论和调研记录见 [`docs/RESEARCH/`](RESEARCH/README.md)

### 5.1 研究课题

| ID | 课题 | 描述 | 状态 | 相关领域 |
|----|------|------|------|----------|
| R01 | Mind Loop | 持续运行的意识循环，不依赖外部输入 | 待研究 | 认知科学、意识理论 |
| R02 | 快/慢系统 | 双系统架构：快速反射 + 深度思考 | → R06 | 行为经济学、认知心理学 |
| R03 | 主动表达 | 非队列式交互，AI 想说就说、可被打断 | 待研究 | 对话系统、语用学 |
| R04 | 情绪与人格 | 情绪状态影响决策，持久的人格特征 | 待研究 | 情感计算、人格心理学 |
| R05 | 记忆系统 | 工作记忆 + 情景记忆 + 语义记忆 + 程序性记忆 | 待研究 | 认知神经科学、记忆心理学 |
| R06 | 混合推理架构 | Reflex → Fast → Slow + Blackboard 共享状态 | **探索中** | 认知架构、神经科学 |
| R07 | 肌肉记忆学习 | 从预定义 → 模仿 → 强化学习 → 自主创造 | 待研究 | 运动学习、强化学习 |

### 5.2 学习资源

> 研究需要大量阅读 AI 论文和神经科学论文

#### AI / 机器学习
- [ ] 强化学习基础（Sutton & Barto）
- [ ] 模仿学习 / Behavioral Cloning
- [ ] Hierarchical RL / Options Framework
- [ ] Transformer 与 Memory（Memory Networks, RAG）
- [ ] LLM Agent 架构（ReAct, Toolformer, AutoGPT 等）

#### 认知科学 / 神经科学
- [ ] 双系统理论（Kahneman - Thinking, Fast and Slow）
- [ ] 全局工作空间理论 (Global Workspace Theory)
- [ ] 认知架构（ACT-R, SOAR, CLARION）
- [ ] 情感神经科学（Damasio - 躯体标记假说）
- [ ] 记忆系统（Tulving - 情景记忆与语义记忆）
- [ ] 运动学习与程序性记忆

#### 论文阅读清单
> 待补充，放在 `docs/RESEARCH/papers/` 目录

---

## 6. 里程碑计划

### Phase 1: 地基 (约 6 个月)

| 版本 | 目标 | 时间 | 状态 |
|------|------|------|------|
| v0.1 | TCP 透明代理 + 配置文件 | 第 1-2 周 | ✅ |
| v0.2 | 协议解析层 | 第 3-4 周 | ✅ |
| v0.2.1 | 地基补强（错误类型、日志、测试、优雅关闭） | 第 5 周 | ✅ |
| v0.3 | 聊天拦截 + LLM 集成 | 第 6-9 周 | ⬜ |
| v0.4 | Bot 登录 + 保活 | 第 9-12 周 | ⬜ |
| v0.5 | 世界感知 + 视野系统 | 第 13-18 周 | ⬜ |
| v0.6 | 原子动作 + 状态反馈 | 第 19-24 周 | ⬜ |

### Phase 2: 技能层 (约 6 个月)

| 版本 | 目标 | 时间 | 状态 |
|------|------|------|------|
| v0.7 | 技能框架 + 预定义技能 | 第 25-32 周 | ⬜ |
| v0.8 | 技能组合 + 寻路系统 | 第 33-40 周 | ⬜ |
| v0.9 | 模仿学习基础 | 第 41-48 周 | ⬜ |

### Phase 3: 认知层 (约 12 个月)

| 版本 | 目标 | 时间 | 状态 |
|------|------|------|------|
| v1.0 | 技能优化 + 基础认知框架 | 第 49-60 周 | ⬜ |
| v1.x | R01-R07 研究与迭代 | 第 61-104 周 | ⬜ |

> Phase 3 是研究性阶段，采用迭代式开发：
> 提出假设 → 实现原型 → 测试验证 → 失败/成功 → 调整 → 重复

---

## 7. 非功能需求

| 需求 | 指标 |
|------|------|
| 延迟 | 代理引入延迟 < 10ms |
| 并发 | 支持 10+ 并发连接 |
| 可维护性 | 代码清晰，有注释，模块化 |
| 可测试性 | 核心模块有单元测试 |
| **可扩展性** | Agent 层可插拔，支持实验不同认知架构 |
| **可观测性** | 认知过程可视化、可调试 |

---

## 8. 系统架构

```
┌─────────────────────────────────────────────────────────────────┐
│                          LOCUS                                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                 Protocol Layer (共享)                   │    │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐    │    │
│  │  │ VarInt  │  │ Packet  │  │Handshake│  │  Login  │    │    │
│  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘    │    │
│  └─────────────────────────────────────────────────────────┘    │
│                              │                                   │
│              ┌───────────────┼───────────────┐                  │
│              ▼                               ▼                  │
│  ┌─────────────────────┐         ┌─────────────────────┐       │
│  │    Proxy Mode       │         │     Bot Mode        │       │
│  │  (Client ↔ Server)  │         │  (Locus = Client)   │       │
│  └──────────┬──────────┘         └──────────┬──────────┘       │
│             │                                │                   │
│             └───────────────┬────────────────┘                  │
│                             ▼                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    World State                           │    │
│  │         位置 / 区块 / 实体 / 背包 / 状态                  │    │
│  └─────────────────────────────────────────────────────────┘    │
│                             │                                    │
│                             ▼                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                    Body Layer                            │    │
│  │              原子动作 API / 状态反馈                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                             │                                    │
│                             ▼                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                   Skills Layer                           │    │
│  │           技能框架 / 肌肉记忆 / 寻路                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                             │                                    │
│                             ▼                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                 Cognition Layer (可插拔)                 │    │
│  │    ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐   │    │
│  │    │ Memory  │  │Reasoning│  │ Emotion │  │  Mind   │   │    │
│  │    │  R05    │  │   R06   │  │   R04   │  │  R01    │   │    │
│  │    └─────────┘  └─────────┘  └─────────┘  └─────────┘   │    │
│  └─────────────────────────────────────────────────────────┘    │
│                             │                                    │
│                             ▼                                    │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │                     LLM Layer                            │    │
│  │                DeepSeek / Qwen / GPT                     │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

---

## 9. 边界 (Out of Scope)

- Minecraft Bedrock Edition
- 正版验证（v1.0 之前）
- 多服务器负载均衡
- Web 管理后台（研究可视化除外）
- 通用插件系统（仅支持认知模块可插拔）

---

## 10. 风险与对策

| 风险 | 影响 | 对策 |
|------|------|------|
| MC 协议复杂 | 开发慢 | 参考 wiki.vg，只实现必要包 |
| LLM 响应慢 | 体验差 | 异步处理，加载提示，多层推理分流 |
| Bot 被服务器踢 | 功能受限 | 研究反作弊机制 |
| 协议版本更新 | 兼容性 | 先支持单一版本，后续抽象 |
| **研究方向错误** | 时间浪费 | 小步验证，快速失败，记录学习 |
| **论文理解困难** | 进度慢 | 建立学习笔记体系，逐步积累 |

---

## 更新日志

| 日期 | 变更 |
|------|------|
| 2026-01-31 | 完成 PRD 初版，确定技术栈和里程碑 |
| 2026-01-31 | v0.1 完成：TCP 透明代理 + 配置文件 |
| 2026-01-31 | 调整开发路径：代理模式 → Bot 模式，共享协议层 |
| 2026-01-31 | 确定 MC 版本：1.20.4 (Protocol 765) |
| 2026-02-03 | 新增 F11b 视野过滤：模拟人类视野限制 |
| 2026-02-03 | 新增 Research 章节：Mind Loop、快/慢系统、主动表达、情绪人格、记忆系统 |
| 2026-02-03 | 新增 R06 混合推理架构，建立 `docs/RESEARCH/` 研究笔记目录 |
| **2026-02-04** | **重大更新：项目重新定位为"仿生 AI Agent 研究平台"** |
| 2026-02-04 | 时间预算从 3 个月调整为 2 年 |
| 2026-02-04 | 新增仿生架构章节，建立分层模型 |
| 2026-02-04 | 功能需求重组为 Phase 1/2/3 结构 |
| 2026-02-04 | 新增 R07 肌肉记忆学习研究方向 |
| 2026-02-04 | 新增学习资源章节（AI 论文 + 神经科学） |
| 2026-02-04 | 新增项目名字由来章节，关联《我不会死》论文 |
| 2026-02-04 | 新增 v0.2.1 地基补强里程碑（错误类型、slog 日志、测试、优雅关闭） |
| 2026-02-04 | v0.2.1 完成，规划 v0.3 聊天拦截 + LLM 集成（T019-T029） |
| 2026-02-04 | v0.2.2 完成：协议压缩/解压支持 (T030)，修复 Nagle 延迟 |
| 2026-02-04 | 目标协议版本从 1.20.4 (765) 更新为 1.21.11 (774) |
| 2026-02-04 | 协议数据源改为 minecraft-data (protocol.json) |
